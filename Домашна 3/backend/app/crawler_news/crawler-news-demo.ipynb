{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b25d65b414ff5a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.023751Z",
     "start_time": "2024-12-25T19:07:55.478157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from app.crawler_news.config import BASE_URL, HEADERS\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import timedelta, date, datetime\n",
    "import aiohttp\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import fitz\n",
    "import re\n",
    "from googletrans import Translator\n",
    "from docx import Document\n",
    "\n",
    "from app.crawler_news.config import BASE_URL, HEADERS, CONTENT_URL, ATTACHMENT_URL"
   ],
   "id": "c6590b275f82afde",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.049851Z",
     "start_time": "2024-12-25T19:07:58.027761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_to_iso(date_str):\n",
    "    date_obj = datetime.strptime(date_str, '%m/%d/%Y')\n",
    "    return date_obj.strftime('%Y-%m-%d')"
   ],
   "id": "36a59da9e82d400c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.102041Z",
     "start_time": "2024-12-25T19:07:58.063406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_news_links(page_content):\n",
    "    list = []\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    news_links = soup.select('#seiNetIssuerLatestNews .container-seinet a')\n",
    "    for row in news_links:\n",
    "        news_id = row[\"href\"].split(\"/\")[-1]\n",
    "        date = str(row.select_one('h4').text.split()[0])\n",
    "\n",
    "        news_dict = {\n",
    "            \"Date\": convert_to_iso(date),\n",
    "            \"ContentURL\": CONTENT_URL + f\"/{news_id}\"\n",
    "        }\n",
    "        list.append(news_dict)\n",
    "\n",
    "    return list"
   ],
   "id": "52b0758b7aae8cbd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.189056Z",
     "start_time": "2024-12-25T19:07:58.110564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_html_text(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    text = soup.get_text(separator=\" \", strip=True)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.replace(\"\\xa0\", \" \")\n",
    "    return text"
   ],
   "id": "90392f392f52e32d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.209799Z",
     "start_time": "2024-12-25T19:07:58.198586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_PDF_text(text):\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    return text"
   ],
   "id": "2efcf1629a30da2d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.392795Z",
     "start_time": "2024-12-25T19:07:58.218335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text_from_docx(byte_code):\n",
    "    doc = Document(byte_code)\n",
    "    text = \"\"\n",
    "    for para in doc.paragraphs:\n",
    "        text += para.text + \"\\n\"\n",
    "    return text"
   ],
   "id": "67b2447bfca6d111",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.466682Z",
     "start_time": "2024-12-25T19:07:58.394793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text_from_pdf(byte_code):\n",
    "    file = fitz.open(stream=byte_code)\n",
    "    text = \"\"\n",
    "    for page_num in range(min(2, file.page_count)):\n",
    "        page = file.load_page(page_num)\n",
    "        text += page.get_text(\"text\")\n",
    "    return text"
   ],
   "id": "68628f3efe342e92",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.591696Z",
     "start_time": "2024-12-25T19:07:58.477218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def fetch_attachment_staro(session, attachment_id, file_type):\n",
    "    CUSTOM_URL = ATTACHMENT_URL + f\"/{attachment_id}\"\n",
    "    async with session.get(CUSTOM_URL) as response:\n",
    "        if response.status == 200:\n",
    "            bytes_content = await response.read()\n",
    "            text = format_PDF_text(extract_text_from_pdf(BytesIO(bytes_content)))\n",
    "            return text\n",
    "    return None"
   ],
   "id": "947c153a190cca98",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.661158Z",
     "start_time": "2024-12-25T19:07:58.602224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_attachment(attachment_id, file_type):\n",
    "    CUSTOM_URL = ATTACHMENT_URL + f\"/{attachment_id}\"\n",
    "    response = requests.get(CUSTOM_URL)\n",
    "    if response.status_code == 200:\n",
    "        bytes_data = BytesIO(response.content)\n",
    "        if file_type == \"pdf\":\n",
    "            text = format_PDF_text(extract_text_from_pdf(bytes_data))\n",
    "        elif file_type == \"docx\":\n",
    "            text = format_PDF_text(extract_text_from_docx(bytes_data))\n",
    "        return text\n",
    "    return None"
   ],
   "id": "66f11f43b2c18094",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.812528Z",
     "start_time": "2024-12-25T19:07:58.663168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_first_link_from_href(text):    \n",
    "    soup = BeautifulSoup(text, 'lxml')    \n",
    "    \n",
    "    link = soup.find('a', href=lambda href: href and href.strip().startswith(('https://seinet.com.mk/document/', 'https://www.seinet.com.mk/document/')))    \n",
    "   \n",
    "    return link['href'] if link else None"
   ],
   "id": "55beb50c8be61386",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:58.871185Z",
     "start_time": "2024-12-25T19:07:58.831591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_content(response_json, is_redirect=False):\n",
    "    content = response_json.get(\"data\", {}).get(\"attachments\", None)\n",
    "    if content:\n",
    "        attachment_id = content[0].get(\"attachmentId\", None)\n",
    "        attachment_type = content[0].get(\"attachmentType\", {}).get(\"mimeType\", \"\")\n",
    "        if attachment_id is not None:\n",
    "            if attachment_type == \"application/pdf\":\n",
    "                return fetch_attachment(attachment_id, \"pdf\")\n",
    "            elif attachment_type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
    "                return fetch_attachment(attachment_id, \"docx\")\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    text = response_json.get(\"data\", {}).get(\"content\", None)  \n",
    "\n",
    "    # Check if redirection is needed   \n",
    "    url_check = extract_first_link_from_href(text)\n",
    "    if url_check:\n",
    "        news_id = url_check.split(\"/\")[-1]        \n",
    "        url = CONTENT_URL + f\"/{news_id}\" \n",
    "        response_json_redirect = requests.get(url).json()        \n",
    "        content_mk = fetch_content(response_json_redirect)         \n",
    "        #return content_mk\n",
    "        return translate_mk_to_en(translator, content_mk)  \n",
    "    return format_html_text(text)"
   ],
   "id": "e86a0413e00dedc5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:07:59.134242Z",
     "start_time": "2024-12-25T19:07:58.893262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_cyrillic(text):\n",
    "    # Replace common misencoded Cyrillic characters\n",
    "    replacements = {\n",
    "        '~': 'ч', '{': 'ш', '}': 'ж', '`': 'ѓ', ']': 'љ', '[': 'њ', '|': 'и',\n",
    "        '@': 'џ', '^': 'ќ',\n",
    "        'A': 'А', 'B': 'Б', 'V': 'В', 'G': 'Г', 'D': 'Д', 'E': 'Е', 'Z': 'З',\n",
    "        'I': 'И', 'J': 'Ј', 'K': 'К', 'L': 'Л', 'M': 'М', 'N': 'Н', 'O': 'О',\n",
    "        'P': 'П', 'R': 'Р', 'S': 'С', 'T': 'Т', 'U': 'У', 'F': 'Ф', 'H': 'Х',\n",
    "        'C': 'Ц', 'Y': 'Ч', 'X': 'Џ', 'Q': 'Ш',\n",
    "        'a': 'а', 'b': 'б', 'v': 'в', 'g': 'г', 'd': 'д', 'e': 'е', 'z': 'з',\n",
    "        'i': 'и', 'j': 'ј', 'k': 'к', 'l': 'л', 'm': 'м', 'n': 'н', 'o': 'о',\n",
    "        'p': 'п', 'r': 'р', 's': 'с', 't': 'т', 'u': 'у', 'f': 'ф', 'h': 'х',\n",
    "        'c': 'ц', 'y': 'ч', 'x': 'џ', 'q': 'ш'\n",
    "    }\n",
    "    for latin_char, cyrillic_char in replacements.items():\n",
    "        text = text.replace(latin_char, cyrillic_char)\n",
    "    return text"
   ],
   "id": "f2f42b6a9c3814bc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:08:01.916554Z",
     "start_time": "2024-12-25T19:07:59.140778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translator = Translator()\n",
    "\n",
    "def translate_mk_to_en(translator, text):\n",
    "    if text is not None:\n",
    "        if isinstance(text, str) and text.strip():\n",
    "            if \"...\" in text:\n",
    "                return None\n",
    "            \n",
    "            normalized_text = normalize_cyrillic(text)\n",
    "            try:\n",
    "                translated_text = translator.translate(normalized_text, src='mk', dest='en')\n",
    "                return translated_text.text\n",
    "            except Exception as e:\n",
    "                print(f\"Translation error: {e}\")\n",
    "                return normalized_text\n",
    "    else:\n",
    "        return None"
   ],
   "id": "5bde41b3c3f4aefd",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:08:01.946498Z",
     "start_time": "2024-12-25T19:08:01.930078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_garbled_text(text):\n",
    "    mixed_words = re.findall(r'\\b[A-Za-z]+\\d+[A-Za-z]*\\b', text)\n",
    "    return len(mixed_words) > 10"
   ],
   "id": "502cf9da586f34f4",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:08:02.412880Z",
     "start_time": "2024-12-25T19:08:02.021069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper function for missing data fetch in Filter 3\n",
    "def fetch_company_news_data(company_name, start_date):\n",
    "    data_to_append = []\n",
    "\n",
    "    if (start_date == None):\n",
    "        end_date = (date.today())\n",
    "        start_date = (end_date - timedelta(days=365 * 10)).isoformat()\n",
    "\n",
    "    latest_date = start_date\n",
    "\n",
    "    news_date_link = []\n",
    "    CUSTOM_URL = BASE_URL + f\"{company_name}\"\n",
    "    response = requests.get(CUSTOM_URL)        \n",
    "    if response.status_code == 200:\n",
    "        page_content = response.text\n",
    "        news_date_link = extract_news_links(page_content)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    if not news_date_link:\n",
    "        return None, None, None\n",
    "\n",
    "    max_date_dict = max(news_date_link, key=lambda x: x['Date'])\n",
    "    max_date = max_date_dict['Date']\n",
    "\n",
    "    if max_date == latest_date:\n",
    "        return None, None, None\n",
    "    elif max_date > latest_date:\n",
    "\n",
    "        filtered_list = [entry for entry in news_date_link if entry['Date'] > latest_date]\n",
    "        latest_date = max_date\n",
    "\n",
    "        for entry in filtered_list:\n",
    "            URL = entry['ContentURL']\n",
    "            response = requests.get(URL)                  \n",
    "            response_json = response.json()\n",
    "            text = fetch_content(response_json)\n",
    "            if text == \"\" or text is None or detect_garbled_text(text):\n",
    "                continue\n",
    "            new_data = {\n",
    "                    \"company\": company_name,\n",
    "                    \"date\": entry['Date'],\n",
    "                    \"content\": text,\n",
    "                    \"sentiment\": \"\"\n",
    "            }\n",
    "            data_to_append.append(new_data)\n",
    "\n",
    "    return company_name, latest_date, data_to_append"
   ],
   "id": "35fdc534619aa584",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T19:13:21.184831Z",
     "start_time": "2024-12-25T19:13:11.171736Z"
    }
   },
   "cell_type": "code",
   "source": "company_name, latest_date, data_to_append = fetch_company_news_data(\"TKPR\", \"2015-01-01\")",
   "id": "f23b6f7d21196d35",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T21:56:33.177312Z",
     "start_time": "2024-12-24T21:56:33.169898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sqlalchemy.orm import Session\n",
    "from app.database.connection import get_db\n",
    "from app.models.stock import StockData, LatestDate\n",
    "\n",
    "def get_all_companies(db: Session = next(get_db())):\n",
    "    print(\"Fetching all unique company names...\")\n",
    "    try:\n",
    "        # Query all records from LatestDate\n",
    "        stocks = db.query(LatestDate.company_name).distinct().limit(15).all()\n",
    "        \n",
    "        # Extract company names from the result\n",
    "        company_names = [stock.company_name for stock in stocks]\n",
    "        \n",
    "        print(f\"Found {len(company_names)} unique companies\")\n",
    "        return company_names\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching company names: {e}\")\n",
    "        return []"
   ],
   "id": "b5566a0647cb1ba0",
   "outputs": [],
   "execution_count": 278
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T21:56:33.582153Z",
     "start_time": "2024-12-24T21:56:33.509002Z"
    }
   },
   "cell_type": "code",
   "source": "company_names = get_all_companies()",
   "id": "d741efde4a34e798",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching all unique company names...\n",
      "Found 15 unique companies\n"
     ]
    }
   ],
   "execution_count": 279
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T21:58:25.980450Z",
     "start_time": "2024-12-24T21:58:25.974919Z"
    }
   },
   "cell_type": "code",
   "source": "company_names",
   "id": "fe5d3e5e4bcce40d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADIN',\n",
       " 'ALK',\n",
       " 'ALKB',\n",
       " 'AMBR',\n",
       " 'AMEH',\n",
       " 'APTK',\n",
       " 'ATPP',\n",
       " 'AUMK',\n",
       " 'BANA',\n",
       " 'BGOR',\n",
       " 'BIKF',\n",
       " 'BIM',\n",
       " 'BLTU',\n",
       " 'CBNG',\n",
       " 'CDHV']"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 283
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3bfada3d70083abd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
